import requests
import json
import time
from pathlib import Path
from typing import List, Dict
import math
from urllib.parse import quote
from datetime import datetime

def create_logger(mode: str):
    """åˆ›å»ºæ—¥å¿—è®°å½•å™¨"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)

    # æ ¹æ®æ¨¡å¼é€‰æ‹©å›ºå®šçš„æ—¥å¿—æ–‡ä»¶å
    log_file = log_dir / f'{mode}_download.log'

    # ç”Ÿæˆæœ¬æ¬¡æ‰§è¡Œçš„å”¯ä¸€æ ‡è¯†
    execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')

    def log_message(message: str):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_line = f"[{timestamp}][{execution_id}] {message}\n"
        print(message)
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_line)

    # å†™å…¥æ‰§è¡Œå¼€å§‹æ ‡è®°
    separator = "="*50
    log_message(f"\n{separator}")
    log_message(f"å¼€å§‹æ–°çš„æ‰§è¡Œ (ID: {execution_id})")
    log_message(f"æ‰§è¡Œæ¨¡å¼: {mode}")
    log_message(separator)

    return log_message, execution_id

def load_json_file(filename: str) -> dict:
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(Path('output') / filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
        return None

def chunk_list(lst: List, chunk_size: int) -> List[List]:
    """å°†åˆ—è¡¨åˆ†å‰²æˆæŒ‡å®šå¤§å°çš„å—"""
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def simulate_download_attachments(is_log=True):
    """æ¨¡æ‹Ÿä¸‹è½½é™„ä»¶çš„å‡½æ•°"""
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    log_message, execution_id = create_logger('simulate')
    # åŠ è½½å¿…è¦çš„æ•°æ®
    file_types = load_json_file('file_types.json')
    employee_data = load_json_file('employee_data.json')

    if not file_types or not employee_data:
        log_message("âŒ æ— æ³•åŠ è½½å¿…è¦çš„æ•°æ®æ–‡ä»¶")
        return

    # æå–å‘˜å·¥IDs
    employee_ids = [emp['cmp_id'] for emp in employee_data]
    id_chunks = chunk_list(employee_ids, 500)

    # æ¨¡æ‹Ÿè¿”å›ç»“æœ
    success_response = {
        "code": "200",
        "sync": False,
        "message": "æ­£åœ¨ä¸‹è½½ï¼ŒæˆåŠŸåä¼šå‘é€ç³»ç»Ÿé€šçŸ¥",
        "warn": "",
        "tipType": "normalTip",
        "url": None
    }

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_requests': 0,
        'successful_requests': 0,
        'file_types_processed': 0
    }

    log_message("ğŸš€ å¼€å§‹æ¨¡æ‹Ÿæ‰¹é‡ä¸‹è½½é™„ä»¶...")

    # ç¬¬ä¸€å±‚å¾ªç¯ï¼šéå†æ–‡ä»¶ç±»å‹
    for file_type in file_types:
        stats['file_types_processed'] += 1
        log_message(f"\nğŸ”„ å¤„ç†æ–‡ä»¶ç±»å‹: {file_type['text']} ({file_type['value']})")

        # ç¬¬äºŒå±‚å¾ªç¯ï¼šéå†IDç»„
        for chunk_index, id_chunk in enumerate(id_chunks):
            stats['total_requests'] += 1

            log_message(f"\nğŸ“¦ å¤„ç†ç¬¬ {chunk_index + 1}/{len(id_chunks)} ç»„ID (å…± {len(id_chunk)} ä¸ªID)")
            log_message(f"ğŸ“„ å½“å‰æ‰¹æ¬¡é¦–ä¸ªID: {id_chunk[0]}")
            log_message(f"ğŸ“„ å½“å‰æ‰¹æ¬¡æœ«ä¸ªID: {id_chunk[-1]}")

            # æ¨¡æ‹ŸæˆåŠŸçš„APIè°ƒç”¨
            stats['successful_requests'] += 1
            log_message(f"âœ… æ¨¡æ‹Ÿè°ƒç”¨æˆåŠŸ: {success_response['message']}")

            # ç¬¬äºŒå±‚å¾ªç¯é—´éš”20ç§’
            if chunk_index < len(id_chunks) - 1:
                log_message("â³ ç­‰å¾…1såå¤„ç†ä¸‹ä¸€ç»„ID...")
                time.sleep(1)

        # ç¬¬ä¸€å±‚å¾ªç¯é—´éš”5åˆ†é’Ÿ
        if file_type != file_types[-1]:
            log_message("\nâ³ ç­‰å¾…20såå¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶ç±»å‹...")
            time.sleep(3)

     # åœ¨ç»“æŸæ—¶æ·»åŠ æ‰§è¡Œç»“æŸæ ‡è®°
    log_message("\n" + "="*50)
    log_message(f"æ‰§è¡Œå®Œæˆ (ID: {execution_id})")
    log_message("="*50 + "\n")

    return stats

def download_attachments(is_log=True):
    """ä¸‹è½½é™„ä»¶çš„ä¸»å‡½æ•°"""
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    log_message, execution_id = create_logger('real')

    # åŠ è½½å¿…è¦çš„æ•°æ®
    file_types = load_json_file('file_types.json')
    employee_data = load_json_file('employee_data.json')

    if not file_types or not employee_data:
        log_message("âŒ æ— æ³•åŠ è½½å¿…è¦çš„æ•°æ®æ–‡ä»¶")
        return

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_requests': 0,
        'successful_requests': 0,
        'file_types_processed': 0
    }

    # æå–å‘˜å·¥IDs
    employee_ids = [emp['cmp_id'] for emp in employee_data]
    log_message(f"ğŸ“Š æ€»å‘˜å·¥æ•°: {len(employee_ids)}")

    # åŸºç¡€URLå’Œè¯·æ±‚å¤´
    base_url = 'https://cloud.italent.cn/api/v2/UI/ExportAttach'

    headers = {
        'Accept': 'application/json, application/xml, text/play, text/html, */*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Content-Type': 'application/json; charset=utf-8',
        'Origin': 'https://cloud.italent.cn',
        'Pragma': 'no-cache',
        'Referer': 'https://cloud.italent.cn/TenantBase',
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
        'X-Sourced-By': 'ajax',
        'fal': quote('ä¸‹è½½é™„ä»¶'),
        'fan': 'extxiazaozhaop',
        'fapp': 'TenantBase',
        'fpl': quote('åœ¨èŒå‘˜å·¥'),
        'fpn': 'TenantBase.InServiceEmployeeNavView',
        'ftc': 'f8d39b50-9ab8-4b5c-8592-7f832fc624c1',
        'fver': '4.11.8',
        'tenant_id': '110088',
        'user_id': '128514306'
    }

    cookies = {
        'xxx': 'xxxx'
    }

    # å°†å‘˜å·¥IDåˆ†ç»„ï¼Œæ¯ç»„æœ€å¤š500ä¸ª
    id_chunks = chunk_list(employee_ids, 500)
    log_message(f"ğŸ“¦ IDåˆ†ç»„æ•°: {len(id_chunks)}")

    log_message("ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½é™„ä»¶...")

    # ç¬¬ä¸€å±‚å¾ªç¯ï¼šéå†æ–‡ä»¶ç±»å‹
    for file_type in file_types:
        stats['file_types_processed'] += 1
        log_message(f"\nğŸ”„ å¤„ç†æ–‡ä»¶ç±»å‹: {file_type['text']} ({file_type['value']})")

        params = {
            'app': 'TenantBase',
            'metaObjName': 'TenantBase.EmployeeInformation',
            'viewName': 'TenantBase.SingleObjectListView.InServiceEmployeeInformationList',
            'exportName': 'extxiazaozhaop',
            'attachColumnName': file_type['value'],
            'attachColumnText': quote(file_type['text']),
            'btnCode_sa': 'extxiazaozhaop',
            'btnMetaObjectName_sa': 'TenantBase.EmployeeInformation',
            'shadow_context': '{"appModel":"italent","uppid":""}',
            '_qsrcapp': 'tenantbase',
            'quark_s': 'a3e6ee79f17ee8e934bc786453c23ae15fe196bee59bac15bb82c6b1b953e337'
        }

        # ç¬¬äºŒå±‚å¾ªç¯ï¼šéå†IDç»„
        for chunk_index, id_chunk in enumerate(id_chunks):
            stats['total_requests'] += 1
            log_message(f"\nğŸ“¦ å¤„ç†ç¬¬ {chunk_index + 1}/{len(id_chunks)} ç»„ID (å…± {len(id_chunk)} ä¸ªID)")
            log_message(f"ğŸ“„ å½“å‰æ‰¹æ¬¡é¦–ä¸ªID: {id_chunk[0]}")
            log_message(f"ğŸ“„ å½“å‰æ‰¹æ¬¡æœ«ä¸ªID: {id_chunk[-1]}")

            # å‡†å¤‡è¯·æ±‚æ•°æ®
            data = {
                "SearchCondition": {
                    "table_data": {
                        "advance": {"cmp_render": {"viewPath": "PureTable", "status": "enable"}},
                        "tableChangeReason": "tableCapacityChange",
                        "hasCheckColumn": True,
                        "ext_data": {"ListViewLabel": "åœ¨èŒå‘˜å·¥åˆ—è¡¨"},
                        "paging": {"capacity": 500, "page": 0},
                        "viewName": "TenantBase.SingleObjectListView.InServiceEmployeeInformationList",
                        "metaObjName": "TenantBase.EmployeeInformation"
                    },
                    "search_data": {
                        "metaObjName": "TenantBase.EmployeeInformation",
                        "searchView": "TenantBase.InServiceEmployeeSearchView",
                        "items": []
                    }
                },
                "IDS": ",".join(id_chunk)
            }

            try:
                response = requests.post(
                    base_url,
                    params=params,
                    headers=headers,
                    cookies=cookies,
                    json=data,
                    timeout=30
                )

                if response.status_code == 200:
                    result = response.json()
                    if result.get('code') == '200':
                        stats['successful_requests'] += 1
                        log_message(f"âœ… æˆåŠŸè§¦å‘ä¸‹è½½: {result.get('message', '')}")
                    else:
                        log_message(f"âŒ è¯·æ±‚å¤±è´¥: {result}")
                else:
                    log_message(f"âŒ HTTPé”™è¯¯: {response.status_code}")

            except Exception as e:
                log_message(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")

            # ç¬¬äºŒå±‚å¾ªç¯é—´éš”
            if chunk_index < len(id_chunks) - 1:
                log_message("â³ ç­‰å¾…10ç§’åå¤„ç†ä¸‹ä¸€ç»„ID...")
                time.sleep(10)

        # ç¬¬ä¸€å±‚å¾ªç¯é—´éš”
        if file_type != file_types[-1]:
            log_message("\nâ³ ç­‰å¾…20såå¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶ç±»å‹...")
            time.sleep(20)

    # åœ¨ç»“æŸæ—¶æ·»åŠ æ‰§è¡Œç»“æŸæ ‡è®°
    log_message("\n" + "="*50)
    log_message(f"æ‰§è¡Œå®Œæˆ (ID: {execution_id})")
    log_message("="*50 + "\n")

    return stats


def main(mode='real'):
    """ä¸»å‡½æ•°ï¼Œå¯é€‰æ‹©è¿è¡Œæ¨¡å¼"""
    if mode == 'simulate':
        print("ğŸ”„ è¿è¡Œæ¨¡æ‹Ÿæ¨¡å¼...")
        stats = simulate_download_attachments()
        print("\nâœ… æ¨¡æ‹Ÿä¸‹è½½ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆ!")
        return stats
    else:
        print("ğŸ”„ è¿è¡Œå®é™…ä¸‹è½½æ¨¡å¼...")
        download_attachments()
        print("\nâœ… å®é™…ä¸‹è½½ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆ!")

if __name__ == "__main__":
    # å¯ä»¥é€šè¿‡ä¿®æ”¹modeå‚æ•°æ¥åˆ‡æ¢æ¨¡å¼
    # mode='simulate' è¿è¡Œæ¨¡æ‹Ÿæ¨¡å¼
    # mode='real' è¿è¡Œå®é™…ä¸‹è½½æ¨¡å¼
    main(mode='simulate')
